{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "%%writefile readme.md\n",
        "\n",
        "#  MedSynth  Privacy-Preserving Synthetic EHR Generator\n",
        "\n",
        "A privacy-aware synthetic Electronic Health Record (EHR) generator with built-in **Membership Inference Defense Metrics**.\n",
        "\n",
        "Built for healthcare AI teams, researchers, and privacy engineers who need realistic patient data — without exposing real patient records.\n",
        "\n",
        "---\n",
        "\n",
        "##  Features\n",
        "\n",
        " **Generate Synthetic EHR Data**\n",
        "- Realistic fields: age, diagnosis, medication, readmission, visit duration\n",
        "- Statistically sampled from real-world distributions\n",
        "\n",
        " **Privacy Defense Metrics**\n",
        "- Detects **Membership Inference Risk**\n",
        "- Uses a shadow classifier to test if synthetic data leaks real patient info\n",
        "- Flags high-risk generation patterns\n",
        "\n",
        "**Data Utility Preservation**\n",
        "- Measures RMSE between real and synthetic distributions\n",
        "- Ensures synthetic data remains useful for downstream ML\n",
        "\n",
        " **Exportable Outputs**\n",
        "- Download as CSV or JSON\n",
        "- Ready for use"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uKeMY9v_99NW",
        "outputId": "7d75c286-6f80-41c7-e27e-fc879869add1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing readme.md\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile requirements.txt\n",
        "pandas\n",
        "numpy\n",
        "matplotlib\n",
        "scikit-learn\n",
        "streamlit\n",
        "fpdf\n",
        "transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YsVDH5fk9rz9",
        "outputId": "0c8c6768-c1a1-47d3-f52a-abd90af647ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting requirements.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "id": "HbvavWp0Z1bA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f1urm79C9zve",
        "outputId": "47bda8f8-a24c-4a7e-b34b-fa00a1a4cb1b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile ehr_schema.py\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "# this is a dictionary i created for the model like a fake model...\n",
        "\n",
        "ehr_fields = {\n",
        "    \"patient_id\": lambda: pd.Series(range(10000, 10100)),\n",
        "    \"age\": lambda: pd.Series([round(x) for x in np.random.uniform(18, 90, size=100)]),\n",
        "    \"gender\": lambda: pd.Series(np.random.choice([\"M\", \"F\", \"O\"], size=100)),\n",
        "    \"race\": lambda: pd.Series(np.random.choice([\"White\", \"Black\", \"Asian\", \"Hispanic\"], size=100)),\n",
        "    \"ethnicity\": lambda: pd.Series(np.random.choice([\"Non-Hispanic\", \"Hispanic\"], size=100)),\n",
        "    \"diagnosis\": lambda: pd.Series(np.random.choice([\n",
        "        \"Hypertension\", \"Diabetes\", \"Asthma\", \"Heart Failure\", \"Obesity\"\n",
        "    ], size=100)),\n",
        "    \"medication\": lambda: pd.Series(np.random.choice([\n",
        "        \"Metformin\", \"Lisinopril\", \"Albuterol\", \"Insulin\", \"Atorvastatin\"\n",
        "    ], size=100)),\n",
        "    \"visit_duration\": lambda: pd.Series(np.random.randint(5, 180, size=100)),\n",
        "    \"readmitted\": lambda: pd.Series(np.random.choice([\"Yes\", \"No\"], size=100))\n",
        "}\n",
        "\n",
        "\n",
        "def generate_synthetic_ehr(num_records=100):\n",
        "    \"\"\"Generate synthetic EHR data based on schema\"\"\"\n",
        "    data = {}\n",
        "    for field, generator in ehr_fields.items():\n",
        "        data[field] = generator()\n",
        "\n",
        "    df = pd.DataFrame(data)\n",
        "    return df.head(num_records)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MoM1E7hj-sIV",
        "outputId": "42cb97b3-2f91-4836-f4b8-0b5b9a750455"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing ehr_schema.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from ehr_schema import generate_synthetic_ehr\n",
        "import numpy as np\n",
        "\n",
        "#This gives you a working CSV of fake but realistic patient records.\n",
        "\n",
        "ehr_data = generate_synthetic_ehr(num_records=100)\n",
        "ehr_data.to_csv(\"synthetic_ehr.csv\", index=False)\n",
        "\n",
        "print(\"Synthetic EHR generated.\")\n",
        "print(ehr_data.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ncoAoZPY_Xny",
        "outputId": "8ce6c628-1d33-4d36-c443-8ee9d2b56638"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Synthetic EHR generated.\n",
            "   patient_id  age gender      race ethnicity      diagnosis    medication  \\\n",
            "0       10000   27      O  Hispanic  Hispanic   Hypertension  Atorvastatin   \n",
            "1       10001   62      M     White  Hispanic         Asthma     Albuterol   \n",
            "2       10002   74      O     White  Hispanic        Obesity  Atorvastatin   \n",
            "3       10003   76      F     Asian  Hispanic         Asthma     Albuterol   \n",
            "4       10004   42      M     White  Hispanic  Heart Failure     Metformin   \n",
            "\n",
            "   visit_duration readmitted  \n",
            "0              15         No  \n",
            "1              98         No  \n",
            "2             153         No  \n",
            "3             125        Yes  \n",
            "4             108        Yes  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile privacy_metrics.py\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "def check_membership_inference_risk(real_data, synthetic_data, target_col=\"diagnosis\"):\n",
        "    \"\"\"\n",
        "    Train a membership inference detector\n",
        "    If model can predict if a record was in training data → high risk\n",
        "    \"\"\"\n",
        "\n",
        "    real_data['membership'] = 1\n",
        "    synthetic_data['membership'] = 0\n",
        "\n",
        "    combined = pd.concat([real_data.sample(frac=0.5),synthetic_data])\n",
        "\n",
        "    X = combined.drop(columns=['membership', target_col],errors='ignore')\n",
        "    y = combined['membership']\n",
        "\n",
        "    X = pd.get_dummies(X)\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3,random_state=42)\n",
        "\n",
        "    model = RandomForestClassifier(n_estimators=50)\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    preds = model.predict(X_test)\n",
        "    acc = accuracy_score(y_test,preds)\n",
        "\n",
        "    print(f\"Membership Inference Accuracy: {acc:.2f}\")\n",
        "    return acc < 0.6 # it means 60%"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IIY7Hk76_3EI",
        "outputId": "ee27be1a-4779-411d-c02e-10c1ffcae4ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing privacy_metrics.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "\n",
        "import gradio as gr\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "from io import BytesIO\n",
        "\n",
        "# Dynamically generate synthetic data to match ANY input schema\n",
        "def generate_synthetic_like(real_df, num_records=100):\n",
        "    \"\"\"Generate synthetic data with same columns and dtypes as real_df\"\"\"\n",
        "    synthetic = pd.DataFrame()\n",
        "\n",
        "    for col in real_df.columns:\n",
        "        col_data = real_df[col].dropna()\n",
        "        if len(col_data) == 0:\n",
        "            synthetic[col] = [\"Unknown\"] * num_records\n",
        "            continue\n",
        "\n",
        "        if pd.api.types.is_numeric_dtype(col_data):\n",
        "            if pd.api.types.is_integer_dtype(col_data):\n",
        "                low, high = int(col_data.min()), int(col_data.max())\n",
        "                synthetic[col] = np.random.randint(low, high + 1, size=num_records)\n",
        "            else:\n",
        "                low, high = float(col_data.min()), float(col_data.max())\n",
        "                synthetic[col] = np.random.uniform(low, high, size=num_records)\n",
        "        else:\n",
        "            # Categorical or string\n",
        "            values = col_data.astype(str).tolist()\n",
        "            synthetic[col] = np.random.choice(values, size=num_records)\n",
        "\n",
        "    return synthetic\n",
        "\n",
        "# Membership Inference Risk Detection\n",
        "def check_membership_inference_risk(real_data, synthetic_data, target_col=None):\n",
        "    try:\n",
        "        # Use first non-ID, non-trivial column as target if not found\n",
        "        if target_col is None:\n",
        "            for col in real_data.columns:\n",
        "                if col.lower() not in ['id', 'patient_id', 'record_id'] and len(real_data[col].dropna()) > 0:\n",
        "                    target_col = col\n",
        "                    break\n",
        "            if target_col is None:\n",
        "                target_col = real_data.columns[0]\n",
        "\n",
        "        real_data = real_data.copy()\n",
        "        synthetic_data = synthetic_data.copy()\n",
        "        real_data['membership'] = 1\n",
        "        synthetic_data['membership'] = 0\n",
        "\n",
        "        # Combine half real + all synthetic\n",
        "        combined = pd.concat([\n",
        "            real_data.sample(frac=0.5, random_state=42),\n",
        "            synthetic_data\n",
        "        ], ignore_index=True)\n",
        "\n",
        "        # Drop target and membership\n",
        "        X = combined.drop(columns=[target_col, 'membership'], errors='ignore')\n",
        "        y = combined['membership']\n",
        "\n",
        "        # One-hot encode categorical features\n",
        "        X = pd.get_dummies(X, max_categories=10)\n",
        "\n",
        "        if X.empty or len(X.columns) == 0:\n",
        "            return False  # Not enough features\n",
        "\n",
        "        from sklearn.model_selection import train_test_split\n",
        "        from sklearn.ensemble import RandomForestClassifier\n",
        "        from sklearn.metrics import accuracy_score\n",
        "\n",
        "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "        model = RandomForestClassifier(n_estimators=50, max_depth=5, random_state=42)\n",
        "        model.fit(X_train, y_train)\n",
        "        acc = accuracy_score(y_test, model.predict(X_test))\n",
        "\n",
        "        print(f\"Membership Inference Attack Accuracy: {acc:.3f}\")\n",
        "        return acc < 0.6  # Safe if below 60%\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Privacy check error: {e}\")\n",
        "        return False  # Default to unsafe on error\n",
        "\n",
        "# Universal file loader with auto-detection\n",
        "def load_data(file_path):\n",
        "    with open(file_path, 'rb') as f:\n",
        "        header = f.read(16)\n",
        "\n",
        "    # Detect Excel files by magic bytes\n",
        "    if header.startswith(b'\\xD0\\xCF\\x11\\xE0\\xA1\\xB1\\x1A\\xE1'):  # Older .xls\n",
        "        return pd.read_excel(file_path, engine='xlrd')\n",
        "    elif header.startswith(b'PK\\x03\\x04'):  # .xlsx or .zip-based\n",
        "        return pd.read_excel(file_path, engine='openpyxl')\n",
        "    else:\n",
        "        # Try CSV with fallback encodings\n",
        "        encodings = ['utf-8', 'latin1', 'cp1252', 'ISO-8859-1']\n",
        "        for enc in encodings:\n",
        "            try:\n",
        "                return pd.read_csv(file_path, encoding=enc)\n",
        "            except Exception:\n",
        "                continue\n",
        "        raise ValueError(f\"Could not decode file with any encoding: {encodings}\")\n",
        "\n",
        "# Main processing function\n",
        "def process_ehr(file):\n",
        "    try:\n",
        "        if file is None:\n",
        "            return pd.DataFrame(), \"Please upload a file.\", None, None\n",
        "\n",
        "        # Load data (auto-detect format & encoding)\n",
        "        real_df = load_data(file.name)\n",
        "\n",
        "        if real_df.empty:\n",
        "            return pd.DataFrame(), \"Uploaded file is empty.\", None, None\n",
        "\n",
        "        # Generate synthetic data with same schema\n",
        "        synthetic_df = generate_synthetic_like(real_df, num_records=100)\n",
        "\n",
        "        # Check privacy risk\n",
        "        is_safe = check_membership_inference_risk(real_df, synthetic_df)\n",
        "        risk_msg = \" Synthetic EHR shows low membership inference risk.\" if is_safe else \"⚠️ High risk: Synthetic data may leak sensitive info.\"\n",
        "\n",
        "        # Save outputs\n",
        "        synthetic_df.to_csv(\"synthetic_ehr.csv\", index=False)\n",
        "        synthetic_df.to_json(\"synthetic_ehr.json\", orient=\"records\", indent=2)\n",
        "\n",
        "        return synthetic_df, risk_msg, \"synthetic_ehr.json\", \"synthetic_ehr.csv\"\n",
        "\n",
        "    except Exception as e:\n",
        "        return pd.DataFrame(), f\" Error processing file: {str(e)}\", None, None\n",
        "\n",
        "# Gradio Interface\n",
        "with gr.Blocks(theme=gr.themes.Soft(), title=\"MedSynth – Universal Synthetic EHR\") as demo:\n",
        "    gr.Markdown(\"\"\"\n",
        "    #  MedSynth  Universal Privacy-Preserving Synthetic Data Generator\n",
        "    Upload **any tabular EHR or patient dataset** (CSV, Excel) — we'll generate realistic synthetic data and check for privacy leaks.\n",
        "    \"\"\")\n",
        "\n",
        "    with gr.Row():\n",
        "        upload = gr.File(label=\" Upload Real EHR (CSV or Excel)\", file_types=[\".csv\", \".xls\", \".xlsx\"])\n",
        "        btn = gr.Button(\" Generate Synthetic Data\", variant=\"primary\")\n",
        "\n",
        "    with gr.Row():\n",
        "        output_df = gr.Dataframe(label=\" Synthetic Data Sample\", interactive=False)\n",
        "\n",
        "    with gr.Row():\n",
        "        risk_text = gr.Textbox(label=\" Privacy Risk Status\")\n",
        "\n",
        "    with gr.Row():\n",
        "        json_out = gr.File(label=\" Download JSON\")\n",
        "        csv_out = gr.File(label=\" Download CSV\")\n",
        "\n",
        "    # Event handler\n",
        "    btn.click(\n",
        "        fn=process_ehr,\n",
        "        inputs=[upload],\n",
        "        outputs=[output_df, risk_text, json_out, csv_out]\n",
        "    )\n",
        "\n",
        "# Launch\n",
        "if __name__ == \"__main__\":\n",
        "    demo.launch(share=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JVaNELu4DHv9",
        "outputId": "296e6dde-6c29-4a12-a17b-ca057bf6184e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "import os\n",
        "\n",
        "os.makedirs(\"/content/drive/MyDrive/MedSynth_Project\", exist_ok=True)\n",
        "shutil.copy(\"synthetic_ehr.csv\", \"/content/drive/MyDrive/MedSynth_Project/synthetic_ehr.csv\")\n",
        "shutil.copy(\"ehr_schema.py\", \"/content/drive/MyDrive/MedSynth_Project/ehr_schema.py\")\n",
        "shutil.copy(\"privacy_metrics.py\", \"/content/drive/MyDrive/MedSynth_Project/privacy_metrics.py\")\n",
        "shutil.copy(\"app.py\", \"/content/drive/MyDrive/MedSynth_Project/app.py\")\n",
        "\n",
        "print(\"All things are safe\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jfj8wYzTr88O",
        "outputId": "d95b525f-849d-48e4-97b3-d265008d7cd2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All things are safe\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python app.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ya637Qwkv8os",
        "outputId": "c18e5a84-b238-432b-a4b3-ed672318efcc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "* Running on local URL:  http://127.0.0.1:7860\n",
            "* Running on public URL: https://5883f179c132eb19ea.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n",
            "/content/app.py:97: DtypeWarning: Columns (4,19) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  return pd.read_csv(file_path, encoding=enc)\n",
            "Privacy check error: get_dummies() got an unexpected keyword argument 'max_categories'\n",
            "Keyboard interruption in main thread... closing server.\n",
            "Killing tunnel 127.0.0.1:7860 <> https://5883f179c132eb19ea.gradio.live\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4aho66sl1_Gg"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}